{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5605848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7b2eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”® SCRIPT DE INFERENCIA - PREDICCIÃ“N PARA 2025-2S\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸ”® SCRIPT DE INFERENCIA - PREDICCIÃ“N PARA 2025-2S\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5566d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Cargando modelos y configuraciÃ³n...\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelos y encoders\n",
    "print(\"\\nðŸ“‚ Cargando modelos y configuraciÃ³n...\")\n",
    "label_encoders = joblib.load('models/label_encoders.pkl')\n",
    "feature_info = joblib.load('models/feature_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbeddc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Modelos disponibles:\n",
      "  1. Random Forest\n",
      "  2. SVM\n",
      "  3. RegresiÃ³n LogÃ­stica\n",
      "  4. XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Modelos disponibles\n",
    "modelos_disponibles = {\n",
    "    '1': ('Random Forest', 'models/random_forest_model.pkl'),\n",
    "    '2': ('SVM', 'models/svm_model.pkl'),\n",
    "    '3': ('RegresiÃ³n LogÃ­stica', 'models/logistic_regression_model.pkl'),\n",
    "    '4': ('XGBoost', 'models/xgboost_model.pkl')\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ¤– Modelos disponibles:\")\n",
    "for key, (nombre, _) in modelos_disponibles.items():\n",
    "    print(f\"  {key}. {nombre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37f8c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ OpciÃ³n invÃ¡lida. Usando Random Forest por defecto.\n",
      "\n",
      "âœ… Modelo seleccionado: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar modelo\n",
    "modelo_seleccionado = input(\"\\nðŸ‘‰ Selecciona el modelo a usar (1-4): \").strip()\n",
    "\n",
    "if modelo_seleccionado not in modelos_disponibles:\n",
    "    print(\"âŒ OpciÃ³n invÃ¡lida. Usando Random Forest por defecto.\")\n",
    "    modelo_seleccionado = '1'\n",
    "\n",
    "nombre_modelo, ruta_modelo = modelos_disponibles[modelo_seleccionado]\n",
    "print(f\"\\nâœ… Modelo seleccionado: {nombre_modelo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c665b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo\n",
    "modelo = joblib.load(ruta_modelo)\n",
    "print(f\"âœ“ Modelo cargado desde '{ruta_modelo}'\")\n",
    "\n",
    "# Cargar datos de inferencia\n",
    "print(\"\\nðŸ“Š Cargando datos de inferencia...\")\n",
    "try:\n",
    "    df_inferencia = pd.read_csv('models/datos_inferencia_2025_2S.csv')\n",
    "    print(f\"âœ“ Datos cargados: {len(df_inferencia)} registros\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ No se encontrÃ³ el archivo 'models/datos_inferencia_2025_2S.csv'\")\n",
    "    print(\"   AsegÃºrate de haber ejecutado el script de entrenamiento primero.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ee01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que tengamos los datos correctos\n",
    "if len(df_inferencia) == 0:\n",
    "    print(\"âŒ No hay datos disponibles para inferencia.\")\n",
    "    exit()\n",
    "\n",
    "# Extraer features\n",
    "X_columns = feature_info['X_columns']\n",
    "X_inferencia = df_inferencia[X_columns]\n",
    "\n",
    "print(f\"\\nðŸ”® Realizando predicciones...\")\n",
    "# Predicciones\n",
    "predicciones = modelo.predict(X_inferencia)\n",
    "probabilidades = modelo.predict_proba(X_inferencia)[:, 1]  # Probabilidad de reprobar\n",
    "\n",
    "# Agregar predicciones al dataframe\n",
    "df_inferencia['PREDICCION'] = predicciones\n",
    "df_inferencia['PROB_REPROBAR'] = probabilidades\n",
    "df_inferencia['PREDICCION_TEXTO'] = df_inferencia['PREDICCION'].apply(\n",
    "    lambda x: 'REPROBARÃ' if x == 1 else 'APROBARÃ'\n",
    ")\n",
    "\n",
    "# Resultados\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ðŸ“Š RESULTADOS DE INFERENCIA\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ DistribuciÃ³n de predicciones:\")\n",
    "print(df_inferencia['PREDICCION_TEXTO'].value_counts())\n",
    "print(f\"\\n  â€¢ Porcentaje predicho de reprobaciÃ³n: {(predicciones == 1).mean()*100:.2f}%\")\n",
    "print(f\"  â€¢ Porcentaje predicho de aprobaciÃ³n: {(predicciones == 0).mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“Š EstadÃ­sticas de probabilidades:\")\n",
    "print(f\"  â€¢ Probabilidad promedio de reprobar: {probabilidades.mean():.4f}\")\n",
    "print(f\"  â€¢ Probabilidad mÃ­nima: {probabilidades.min():.4f}\")\n",
    "print(f\"  â€¢ Probabilidad mÃ¡xima: {probabilidades.max():.4f}\")\n",
    "print(f\"  â€¢ DesviaciÃ³n estÃ¡ndar: {probabilidades.std():.4f}\")\n",
    "\n",
    "# Estudiantes en riesgo (probabilidad > 0.5)\n",
    "estudiantes_riesgo = df_inferencia[df_inferencia['PROB_REPROBAR'] > 0.5]\n",
    "print(f\"\\nâš ï¸ Estudiantes en ALTO RIESGO de reprobar (prob > 0.5): {len(estudiantes_riesgo)}\")\n",
    "\n",
    "# Estudiantes en riesgo moderado (0.3 < prob <= 0.5)\n",
    "estudiantes_riesgo_moderado = df_inferencia[\n",
    "    (df_inferencia['PROB_REPROBAR'] > 0.3) & (df_inferencia['PROB_REPROBAR'] <= 0.5)\n",
    "]\n",
    "print(f\"âš ï¸ Estudiantes en RIESGO MODERADO (0.3 < prob <= 0.5): {len(estudiantes_riesgo_moderado)}\")\n",
    "\n",
    "# Guardar resultados\n",
    "output_file = f'models/predicciones_2025_2S_{nombre_modelo.replace(\" \", \"_\").lower()}.csv'\n",
    "df_inferencia.to_csv(output_file, index=False)\n",
    "print(f\"\\nðŸ’¾ Predicciones guardadas en '{output_file}'\")\n",
    "\n",
    "# Mostrar algunos ejemplos\n",
    "print(f\"\\nðŸ“‹ EJEMPLOS DE PREDICCIONES (primeros 10 registros):\")\n",
    "print(\"=\"*80)\n",
    "columnas_mostrar = ['COD_ESTUDIANTE', 'COD_MATERIA_ACAD_MO', 'PREDICCION_TEXTO', 'PROB_REPROBAR']\n",
    "if 'COD_ESTUDIANTE' in df_inferencia.columns:\n",
    "    print(df_inferencia[columnas_mostrar].head(10).to_string(index=False))\n",
    "else:\n",
    "    print(df_inferencia[['PREDICCION_TEXTO', 'PROB_REPROBAR']].head(10).to_string(index=False))\n",
    "\n",
    "# Si tenemos las etiquetas reales, calcular mÃ©tricas\n",
    "if 'REPROBO' in df_inferencia.columns:\n",
    "    from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "    \n",
    "    y_real = df_inferencia['REPROBO']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ðŸ“Š EVALUACIÃ“N DEL MODELO EN DATOS DE INFERENCIA (2025-2S)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    accuracy = accuracy_score(y_real, predicciones)\n",
    "    roc_auc = roc_auc_score(y_real, probabilidades)\n",
    "    \n",
    "    print(f\"\\nâœ… MÃ©tricas de rendimiento:\")\n",
    "    print(f\"  â€¢ Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  â€¢ ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Classification Report:\")\n",
    "    print(classification_report(y_real, predicciones, target_names=['Aprobado', 'Reprobado']))\n",
    "    \n",
    "    cm = confusion_matrix(y_real, predicciones)\n",
    "    print(f\"\\nðŸ“Š Matriz de ConfusiÃ³n:\")\n",
    "    print(f\"  [[TN={cm[0,0]}, FP={cm[0,1]}],\")\n",
    "    print(f\"   [FN={cm[1,0]}, TP={cm[1,1]}]]\")\n",
    "    \n",
    "    print(f\"\\n  InterpretaciÃ³n:\")\n",
    "    print(f\"  â€¢ Verdaderos Negativos (TN): {cm[0,0]} - Correctamente predichos como APROBARÃ\")\n",
    "    print(f\"  â€¢ Falsos Positivos (FP): {cm[0,1]} - Incorrectamente predichos como REPROBARÃ\")\n",
    "    print(f\"  â€¢ Falsos Negativos (FN): {cm[1,0]} - Incorrectamente predichos como APROBARÃ\")\n",
    "    print(f\"  â€¢ Verdaderos Positivos (TP): {cm[1,1]} - Correctamente predichos como REPROBARÃ\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… INFERENCIA COMPLETADA\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
